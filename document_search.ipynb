{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Search Pipeline\n",
    "\n",
    "Ask anything related to documment and get answer based on the context from document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: vectorshift in c:\\users\\paras\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.0.66)\n",
      "Requirement already satisfied: networkx==3.1 in c:\\users\\paras\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from vectorshift) (3.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.2 -> 24.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "! pip install vectorshift --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline Overview\n",
    "\n",
    "This pipeline takes two inputs, a document and a question. You will get answer from LLM based on context provided from the document.\n",
    "![alt text](images/document_search/1-overview.png \"pipeline overview\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import vectorshift as vs\n",
    "from vectorshift.node import InputNode, URLLoaderNode, TextNode, SemanticSearchNode, OpenAILLMNode, OutputNode, ChatMemoryNode\n",
    "from vectorshift.pipeline import Pipeline\n",
    "from vectorshift.knowledge_base import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vs.api_key=\"YOUR_API_KEY\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input Nodes\n",
    "Input seperated into two, document input and question. File loader is included in file loader, so you dont need to define it.\n",
    "![alt text](images/document_search/2-inputs.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_input = InputNode(name=\"document_input\",input_type=\"file\")\n",
    "questions_input = InputNode(name=\"question\",input_type=\"text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_node = SemanticSearchNode(query_input=[questions_input.output()], documents_input=[document_input.output()], max_docs_per_query=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_text = \"\"\"You are a helpful assistant that answers User Question based on Context\"\"\"\n",
    "system_text_node = TextNode(text=system_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAILLMNode(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    system_input=system_text_node.output(),\n",
    "    prompt_input=questions_input.output(),\n",
    "    text_inputs={\"context\":search_node.output()}\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_node = OutputNode(name=\"output\",output_type=\"text\",input=llm.output())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_search_pipeline_nodes = [\n",
    "    document_input, questions_input, search_node, system_text, llm, system_text_node, output_node\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'node_type'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m document_search_pipeline \u001b[38;5;241m=\u001b[39m \u001b[43mPipeline\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mDocument Searchss\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdescription\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mAsk your document questions and get answers\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdocument_search_pipeline_nodes\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\paras\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\vectorshift\\pipeline.py:159\u001b[0m, in \u001b[0;36mPipeline.__init__\u001b[1;34m(self, name, description, nodes, id, branch_id, **kwargs)\u001b[0m\n\u001b[0;32m    156\u001b[0m \u001b[38;5;66;03m# assign each node an ID and increment self.node_type_counts - before\u001b[39;00m\n\u001b[0;32m    157\u001b[0m \u001b[38;5;66;03m# adding edges, all nodes must have IDs first\u001b[39;00m\n\u001b[0;32m    158\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m node \u001b[38;5;129;01min\u001b[39;00m nodes:\n\u001b[1;32m--> 159\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_add_node\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;66;03m# Create edges: An edge is a dict following the JSON structure. All\u001b[39;00m\n\u001b[0;32m    162\u001b[0m \u001b[38;5;66;03m# edges in the computation graph defined by the nodes terminate at some\u001b[39;00m\n\u001b[0;32m    163\u001b[0m \u001b[38;5;66;03m# node, i.e. are in the node's _inputs. So it should suffice to parse\u001b[39;00m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;66;03m# through every node's _inputs and create an edge for each one.\u001b[39;00m\n\u001b[0;32m    165\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39medges: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m]] \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32mc:\\Users\\paras\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\vectorshift\\pipeline.py:469\u001b[0m, in \u001b[0;36mPipeline._add_node\u001b[1;34m(self, node)\u001b[0m\n\u001b[0;32m    467\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_add_node\u001b[39m(\u001b[38;5;28mself\u001b[39m, node: NodeTemplate):\n\u001b[0;32m    468\u001b[0m     \u001b[38;5;66;03m# assign a fresh new ID to the node\u001b[39;00m\n\u001b[1;32m--> 469\u001b[0m     t \u001b[38;5;241m=\u001b[39m \u001b[43mnode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnode_type\u001b[49m\n\u001b[0;32m    470\u001b[0m     type_counter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnode_type_counts[t] \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    471\u001b[0m     node_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mt\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m-\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtype_counter\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute 'node_type'"
     ]
    }
   ],
   "source": [
    "document_search_pipeline = Pipeline(\n",
    "    name=\"Document Searchss\",\n",
    "    description=\"Ask your document questions and get answers\",\n",
    "    nodes=document_search_pipeline_nodes\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
