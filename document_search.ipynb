{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Search Pipeline\n",
    "\n",
    "Ask anything related to documment and get answer based on the context from document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: vectorshift in c:\\users\\paras\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.0.66)\n",
      "Requirement already satisfied: networkx==3.1 in c:\\users\\paras\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from vectorshift) (3.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.2 -> 24.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "! pip install vectorshift --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline Overview\n",
    "\n",
    "This pipeline takes two inputs, a document and a question. You will get answer from LLM based on context provided from the document.\n",
    "![alt text](images/document_search/1-overview.png \"pipeline overview\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import vectorshift as vs\n",
    "from vectorshift.node import InputNode, URLLoaderNode, TextNode, SemanticSearchNode, OpenAILLMNode, OutputNode, ChatMemoryNode\n",
    "from vectorshift.pipeline import Pipeline\n",
    "from vectorshift.knowledge_base import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vs_api_key = \"YOUR_API_KEY\"\n",
    "vs.api_key = vs_api_key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input Nodes\n",
    "Input seperated into two, document input and question. File loader is included in file loader, so you dont need to define it.\n",
    "![alt text](images/document_search/2-inputs.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_input = InputNode(name=\"document_input\",input_type=\"file\")\n",
    "questions_input = InputNode(name=\"question\",input_type=\"text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_node = SemanticSearchNode(query_input=[questions_input.output()], documents_input=[document_input.output()], max_docs_per_query=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_text = \"\"\"You are a helpful assistant that answers User Question based on Context\"\"\"\n",
    "system_text_node = TextNode(text=system_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAILLMNode(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    system_input=system_text_node.output(),\n",
    "    prompt_input=questions_input.output(),\n",
    "    text_inputs={\"context\":search_node.output()}\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_node = OutputNode(name=\"output\",output_type=\"text\",input=llm.output())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_search_pipeline_nodes = [\n",
    "    document_input, questions_input, search_node, system_text, llm, system_text_node, output_node\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_search_pipeline = Pipeline(\n",
    "    name=\"Document Searchss\",\n",
    "    description=\"Ask your document questions and get answers\",\n",
    "    nodes=document_search_pipeline_nodes\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = vectorshift.deploy.Config(\n",
    "    api_key=vs_api_key,\n",
    ")\n",
    "\n",
    "config.save_new_pipeline(csv_search_pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run The Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline.fetch(pipeline_name='Vectorshift Chatbot')\n",
    "\n",
    "response = pipeline.run(\n",
    "    inputs = {\"input_1\": \"https://www.vectorshift.ai/\", \"input_2\": \"/files/cv.pdf\"},\n",
    "    api_key= vs_api_key\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
